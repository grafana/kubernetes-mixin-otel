receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

  hostmetrics:
    scrapers:
      cpu:
        metrics:
          system.cpu.logical.count:
            enabled: true
      load: {}
      memory:
        metrics:
          system.memory.limit:
            enabled: true
      disk: {}
      filesystem: {}
      network: {}

  # Scrape simulated kubelet resource metrics from KWOK controller
  prometheus/kwok:
    config:
      scrape_configs:
        - job_name: 'kwok-resource-metrics'
          scrape_interval: 30s
          static_configs:
            - targets: ['${env:KWOK_CONTROLLER_IP}:10247']
          metrics_path: /metrics/nodes/node-000000/metrics/resource
          # Note: This only scrapes node-000000. For all nodes, use service discovery
          # or generate targets dynamically

  k8s_cluster:
    auth_type: kubeConfig
    collection_interval: 30s
    node_conditions_to_report:
      - Ready
      - MemoryPressure
      - DiskPressure
      - PIDPressure
    allocatable_types_to_report:
      - cpu
      - memory
      - storage
    metadata_collection_interval: 5m

processors:
  k8sattributes:
    auth_type: kubeConfig
    extract:
      otel_annotations: true

  resource/k8sclustername:
    attributes:
      - key: k8s.cluster.name
        action: upsert
        value: ${env:CLUSTER_NAME}

  resource/hostname:
    attributes:
      - key: k8s.node.name
        action: upsert
        value: ${env:K8S_NODE_NAME}
      - key: host.name
        action: upsert
        from_attribute: k8s.node.name

  transform/copy_node_name:
    metric_statements:
      - context: datapoint
        statements:
          - set(datapoint.attributes["k8s.node.name"], resource.attributes["k8s.node.name"]) where resource.attributes["k8s.node.name"] != nil
          - set(datapoint.attributes["host.name"], resource.attributes["host.name"]) where resource.attributes["host.name"] != nil

  resourcedetection:
    detectors: [system]
    timeout: 2s
    override: true

  batch: {}

exporters:
  # Send metrics to local LGTM (grafana/otel-lgtm container)
  otlphttp/metrics:
    endpoint: http://host.docker.internal:4318
    tls:
      insecure: true

  # Prometheus debug exporter
  prometheus:
    endpoint: "0.0.0.0:8889"
    resource_to_telemetry_conversion:
      enabled: true

extensions:
  health_check: {}

service:
  extensions: [health_check]

  pipelines:
    metrics:
      receivers: [otlp, hostmetrics, k8s_cluster, prometheus/kwok]
      processors:
        - resourcedetection
        - k8sattributes
        - resource/k8sclustername
        - resource/hostname
        - transform/copy_node_name
        - batch
      exporters: [otlphttp/metrics, prometheus]

