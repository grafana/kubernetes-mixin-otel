receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

  hostmetrics:
    scrapers:
      cpu:
        metrics:
          system.cpu.logical.count:
            enabled: true
      load: {}
      memory:
        metrics:
          system.memory.limit:
            enabled: true
      disk: {}
      filesystem: {}
      network: {}

  # Collect kubelet stats from kwok-stats-proxy (simulates /stats/summary for KWOK)
  kubeletstats:
    auth_type: none
    endpoint: ${env:STATS_PROXY_ENDPOINT}
    collection_interval: 30s
    insecure_skip_verify: true
    metric_groups:
      - node
      - pod
      - container

  k8s_cluster:
    auth_type: kubeConfig
    collection_interval: 30s
    node_conditions_to_report:
      - Ready
      - MemoryPressure
      - DiskPressure
      - PIDPressure
    allocatable_types_to_report:
      - cpu
      - memory
      - storage
    metadata_collection_interval: 5m

processors:
  k8sattributes:
    auth_type: kubeConfig
    extract:
      otel_annotations: true

  resource/k8sclustername:
    attributes:
      - key: k8s.cluster.name
        action: upsert
        value: ${env:CLUSTER_NAME}

  resourcedetection:
    detectors: [system]
    timeout: 2s
    override: true

  batch: {}

exporters:
  # Send metrics to local LGTM (grafana/otel-lgtm container)
  otlphttp/metrics:
    endpoint: http://host.docker.internal:4318
    tls:
      insecure: true
    sending_queue:
      batch:
        sizer: bytes
        max_size: 4194304

  # Prometheus debug exporter
  prometheus:
    endpoint: "0.0.0.0:8889"
    resource_to_telemetry_conversion:
      enabled: true

extensions:
  health_check: {}

service:
  extensions: [health_check]

  pipelines:
    metrics:
      receivers: [otlp, hostmetrics, k8s_cluster, kubeletstats]
      processors:
        - resourcedetection
        - k8sattributes
        - resource/k8sclustername
        - batch
      exporters: [otlphttp/metrics, prometheus]

